{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Stack – Aligning a Stack of Images Based On a Fixed Target Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Daniel Sieber, Samuel John\n",
    "\n",
    "#### Abstract\n",
    "\n",
    "Images that have been cut or grinded from a block are oftentimes not aligned. This IPython notebook uses a fixed target structure in the image (in our case the outline of an overmold) that is visible in all images of the stack to find the best affine transform which aligns all images to the given target. The target is based on one image of the stack where only the fixed structure remains visible and the remaining area is made transparent.\n",
    "\n",
    "#### Repository\n",
    "\n",
    "<https://github.com/awesomecodingskills/reconstruct_volume_from_RGB_slices>\n",
    "\n",
    "#### TODO\n",
    "\n",
    "- Write better Abstract\n",
    "- Add \"How to cite\" statement and link to paper (DOI) here\n",
    "- Improve code commenting\n",
    "\n",
    "\n",
    "#### [The MIT License (MIT)](http://opensource.org/licenses/MIT)\n",
    "\n",
    "Copyright (c) 2015 Daniel Sieber, Samuel John\n",
    "\n",
    "\n",
    "<div style=\"font-size:7pt;\">\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in\n",
    "all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "THE SOFTWARE.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot in this IPython Notebook instead of opening separate windows\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# Import external modules used by this script\n",
    "from skimage import img_as_float, io, transform\n",
    "\n",
    "# Scientific Python and typed array/matrix support (by including NumPy)\n",
    "import scipy as sp\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Write Python objects to disk.\n",
    "# TODO: This should be replaced by some HDF5 files that store the transformation matrix\n",
    "import pickle\n",
    "\n",
    "# Parsing svg files and accessing paths in there\n",
    "from xml.dom import minidom\n",
    "import svg.path  # you might need to `pip install svg.path`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our own modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pattern_finder_gpu\n",
    "from pattern_finder_gpu import center_roi_around, find_pattern_rotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of functions used by this script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_overlay(image, svg_path, ax=None, figsize=(15,15)):\n",
    "    \"\"\"\n",
    "    This function plots a path from an SVG_xml and shows it on top of image.\n",
    "    - `image`: ndarray\n",
    "    - `svg_path`: svg path object, see `svg.path`\n",
    "    - `ax`: Matplotlib axes object\n",
    "    - `figsize`: size of figure in inch (see Matplotlib)\n",
    "    \"\"\"\n",
    "    \n",
    "    #Create new figure and axes\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_axes([0,0,1,1])\n",
    "    #Show transformed image\n",
    "    ax.imshow(image, interpolation='nearest')\n",
    "    #Sample 10000 points from the path and get their coordinates\n",
    "    numberSamplePoints = 10000\n",
    "    overlay_coords = sp.array([svg_path.point(p/numberSamplePoints) for p in range(numberSamplePoints)])\n",
    "    #Plot the path\n",
    "    ax.plot(overlay_coords.real, overlay_coords.imag, color='magenta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_parameters(T, end=\"\\n\"):\n",
    "    \"\"\"\n",
    "    Function that prints the components an affine transformation matrix on screen.\n",
    "    - `T`: skimage.transform.AffineTransformation object\n",
    "    \n",
    "    Meaning of outputs printed:\n",
    "        \n",
    "        x,y: Translations in X,Y direction\n",
    "        r: Rotation in degrees\n",
    "        sx,sy: Scale in X,Y direction\n",
    "        shear: Shear\n",
    "    \"\"\"\n",
    "    print(\" x = {x:.0f} y = {y:.0f} r = {rot:.3f}º sx = {sx:.3f} sy = {sy:.3f} shear = {shear:.4f}\"\n",
    "          .format(x=sp.float64(T.translation[0]),\n",
    "                  y=sp.float64(T.translation[1]),\n",
    "                  rot=sp.rad2deg(T.rotation),\n",
    "                  sx=T.scale[0],\n",
    "                  sy=T.scale[1], \n",
    "                  shear=T.shear),\n",
    "          end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_stack(images, target, rough_search_strategy, fine_search_strategy,\n",
    "                plot=False, write_files=False, PF=None):\n",
    "    \"\"\"\n",
    "    - `images`: ndarray or skimage.io.collection.ImageCollection object containing image to be aligned\n",
    "    - `target`: ndarray containing outline to be searched\n",
    "    - `rough_search_strategy`: list of dictionaries containing values for rescale(float between 0 and 1),\n",
    "                       angle range to be searched ([start,end,no_steps]), and ROI size (height,width)\n",
    "    - `fine_search_strategy`: list of dictionaries containing the values for the fine tuning optimizer:\n",
    "        + rescale: The rescale factor (float between 0 and 1) to compute the similarity during optimization.\n",
    "    - `plot`: Define level of detail for plotting[False,True,'all']\n",
    "    - `write_files`: boolean to indicate whether results are saved to file\n",
    "    - `PF`: PatternFinder instance (optional)\n",
    "    \"\"\"    \n",
    "\n",
    "    # Create Patternfinder if none exists\n",
    "    if PF is None:\n",
    "        PF = PatternFinder(partitions=10)\n",
    " \n",
    "    # Initialize list which will later on contain transformations for all files in \"images\"\n",
    "    final_transforms = []\n",
    "    \n",
    "    # Check whether the input is an ImageCollection\n",
    "    use_ic = False\n",
    "    if type(images) is io.ImageCollection:\n",
    "        use_ic = True       \n",
    "        # Some tif images contain actually two images (a big one and a smaller\n",
    "        # thumbnail preview). image_collection therefore seems to generate two\n",
    "        # entries for each of the files. The load_func, however, always loads\n",
    "        # the big one, which is then actaully loaded twice. So we use a `set`\n",
    "        # to make this unique and drop duplicates.\n",
    "        imagelist = sorted(set(images.files))\n",
    "    else:\n",
    "        imagelist = images\n",
    "\n",
    "    for im_nr, image_file in enumerate(imagelist):\n",
    "        if use_ic:\n",
    "            im = img_as_float(images.load_func(image_file))\n",
    "            print(\"\\n\\nImage Nr. {0} {1}\".format(im_nr, image_file))\n",
    "        else:\n",
    "            im = img_as_float(image_file)\n",
    "            print(\"\\n\\nImage Nr. {0}\".format(im_nr))\n",
    "            \n",
    "        print(\"\\n === BRUTE FORCE ALIGNMENT ===\", flush=True)\n",
    "        rough_trans, value = align_image_brute_force(im, target, rough_search_strategy, plot, write_files, PF)\n",
    "\n",
    "        if plot == 'all':\n",
    "            im_trans = transform.warp(im, rough_trans, output_shape=[target.shape[0], target.shape[1]])\n",
    "            plot_overlay(im_trans, svg_path)\n",
    "            plt.show()\n",
    "        \n",
    "        # Print parameters of rough alignment\n",
    "        print_parameters(rough_trans)\n",
    "        \n",
    "        print(\"\\n === LOCAL OPTIMIZATION ===\")\n",
    "\n",
    "        trans = rough_trans\n",
    "        for i, strategy in enumerate(fine_search_strategy):\n",
    "            print(\"\\n --- Round {i} ---\".format(i=i+1))\n",
    "            print(\"    strategy = {}\".format(strategy))\n",
    "            # Update the refined `trans` for each round in this search strategy\n",
    "            trans, res = align_image_local_optim(im, target, trans,\n",
    "                                                 PF=PF, plot=plot, **strategy)\n",
    "            # Print parameters of local optimization\n",
    "            print(res.message)\n",
    "\n",
    "\n",
    "        final_transforms.append(trans)\n",
    "        im_trans = transform.warp(im, trans, output_shape=[target.shape[0], target.shape[1]])\n",
    "        plot_overlay(im_trans, svg_path)\n",
    "                \n",
    "        if write_files:\n",
    "            io.imsave(write_files + os.sep + os.path.basename(image_file)[0:3] + \".PNG\", im_trans)\n",
    "            plt.savefig(write_files + os.sep + \"Plot_\" + os.path.basename(image_file)[0:3] + \".PNG\", dpi=100)\n",
    "        \n",
    "        if plot == 'all':\n",
    "            plt.show()\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "    if write_files:\n",
    "        # Write final transformations to file\n",
    "        with open(\"../EXPORT/transforms.pkl\",'wb') as f:\n",
    "            pickle.dump(final_transforms, f)\n",
    "    \n",
    "    del PF\n",
    "    return final_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def align_image_brute_force(image, target, search_strategy, plot=False, write_files=False, PF=None):\n",
    "    if PF is None:\n",
    "        PF = PatternFinder(partitions=10)\n",
    "    \n",
    "    target_center = sp.array(target.shape[:2]) / 2. - 0.5\n",
    "    im_center = sp.array(image.shape[:2]) / 2. - 0.5\n",
    "    \n",
    "    best_angle = 0.0\n",
    "    best_coord = im_center\n",
    "    best_value = None\n",
    "\n",
    "    for nr, search_phase in enumerate(search_strategy):\n",
    "        print(\"\\nSearch phase {0}\".format(nr), flush=True)\n",
    "        angle_range = (search_phase[\"angle_range\"][0] + best_angle,\n",
    "                       search_phase[\"angle_range\"][1] + best_angle,\n",
    "                       search_phase[\"angle_range\"][2])\n",
    "        res = find_pattern_rotated(PF, target, image, \n",
    "                                   rescale=search_phase[\"rescale\"],\n",
    "                                   rotate=angle_range,\n",
    "                                   roi_center=best_coord,\n",
    "                                   roi_size=search_phase[\"roi_hw\"], \n",
    "                                   plot=plot)\n",
    "        best_res = res[sp.argmin([r[4] for r in res])]  # best_res is the best result in the res list\n",
    "        best_angle = best_res[0]  # The rotation angle is the 0-th element in best_res\n",
    "        best_coord = best_res[3]  # The coordinates are in the 2-nd element\n",
    "        best_value = best_res[4]  # The actual value is the 3-rd element\n",
    "                          \n",
    "        move_to_center = transform.AffineTransform(translation=-(best_coord)[::-1])\n",
    "        move_back = transform.AffineTransform(translation=(best_coord[::-1]))\n",
    "        rotation = transform.AffineTransform(rotation=-sp.deg2rad(best_angle))\n",
    "        translation = transform.AffineTransform(translation=sp.asmatrix((best_coord-target_center)[::-1]))\n",
    "\n",
    "        final_trans = translation + move_to_center + rotation + move_back\n",
    "    return final_trans, best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def align_image_local_optim(image, target, transMatrix, PF=None, plot=False, **kws):\n",
    "    \n",
    "    rescale = kws.pop(\"rescale\", 1)  # Get and remove \"rescale\" from kws and if not in there, default to 1\n",
    "    \n",
    "    if PF is None:\n",
    "        PF = PatternFinder(partitions=10)\n",
    "    \n",
    "    # Convert initialGuess transformation matrix into an ndarray with six entries for the DOFs\n",
    "    initialGuess = sp.asarray(transMatrix.params).flatten()[0:6]\n",
    "    \n",
    "    target_scaled = transform.rescale(target, rescale)\n",
    "    im_scaled = transform.rescale(image, rescale)\n",
    "\n",
    "    # Set (and upload to GPU) the image already now,\n",
    "    # because during optimization it is not changed at all.\n",
    "    PF.set_image(im_scaled)\n",
    "\n",
    "    res = sp.optimize.minimize(loss_fcn,\n",
    "                               initialGuess,\n",
    "                               args=(PF, target_scaled, im_scaled, rescale, plot), \n",
    "                               method='Nelder-Mead',\n",
    "                               **kws)\n",
    "    print()\n",
    "    return transform.AffineTransform(sp.asmatrix(sp.append(res.x,[0,0,1]).reshape(3,3))), res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss_fcn(guess, PF, target_scaled, image_scaled, rescale, plot):\n",
    "    \n",
    "    T = transform.AffineTransform(sp.asmatrix(sp.append(guess,[0,0,1]).reshape(3,3)))\n",
    "    scale_mat = sp.asmatrix(transform.AffineTransform(scale=[rescale, rescale]).params)\n",
    "    combined_transform = scale_mat * T.params * scale_mat.I    \n",
    "        \n",
    "    # Create \"fake\" ROI around image center with size one\n",
    "    roi_center = sp.array(image_scaled.shape[:2])/2.0 - 0.5\n",
    "    roi = pattern_finder_gpu.center_roi_around(roi_center, [1,1])\n",
    "\n",
    "    # Execute Pattern Finder and calculate best match\n",
    "    transformed_targed = transform.warp(target_scaled,\n",
    "                                        combined_transform.I,\n",
    "                                        output_shape=image_scaled.shape[:2])\n",
    "    PF.set_pattern(transformed_targed)\n",
    "    out, min_coords, value = PF.find(roi=roi)\n",
    "\n",
    "    if plot == 'all':\n",
    "        print_parameters(T, end=\"\")\n",
    "        print(\" => {}\".format(value), flush=True)\n",
    "\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Start of main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Target File containing the template for the further template matching\n",
    "target = img_as_float(io.imread(\"../ZETA/Target_Zeta_110_20_smooth_edges_filled_quadratic.png\"))\n",
    "# Load SVG file containing outline of template and extract path frpom xml format\n",
    "svg_xml = minidom.parse(\"../ZETA/Target_ZETA_110_20_smooth_filled_edges_quadratic.SVG\")\n",
    "svg_path = svg.path.parse_path([path.getAttribute('d') for path in svg_xml.getElementsByTagName('path')][0])\n",
    "svg_xml.unlink()\n",
    "# Load image collection\n",
    "ic = io.ImageCollection('../ZETA/193.tif')\n",
    "# Assure the border of the target is transparent\n",
    "target[0,:,3] = 0.0\n",
    "target[-1,:,3] = 0.0\n",
    "target[:,0,3] = 0.0\n",
    "target[:,-1,3] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quick check if the target image and the SVG outline match\n",
    "plot_overlay(target, svg_path, figsize=(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Definition of search strategy for brute force\n",
    "rough_search_strategy = [dict(rescale=0.1, angle_range=(   0,  0,  1), roi_hw=(51, 51)),\n",
    "                         dict(rescale=0.1, angle_range=( 55, 35, 101), roi_hw=(15, 15))]\n",
    "\n",
    "fine_search_strategy = [dict(rescale=0.1, tol=10.0),\n",
    "                        dict(rescale=0.3, tol=1.0)] # On 0.3 I really get perfect results. 0.2 might do too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Execution of image alignment\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")  # strangely \"once\" does not seem to do what it says... so for now just \"shut up\"\n",
    "    result = build_stack(ic,\n",
    "                         target,\n",
    "                         rough_search_strategy=rough_search_strategy,\n",
    "                         fine_search_strategy=fine_search_strategy,\n",
    "                         PF=pattern_finder_gpu.PatternFinder(partitions=1),\n",
    "                         write_files=False,\n",
    "                         plot='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
